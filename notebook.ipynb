{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 10:41:22.794977: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 10:41:23.199618: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 10:41:23.419606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 10:41:24.751295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhonemeRecognizer(tf.keras.Model):\n",
    "    def __init__(self, num_phonemes):\n",
    "        super(PhonemeRecognizer, self).__init__()\n",
    "        self.conv1d_layer = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "        self.pooling_layer = tf.keras.layers.MaxPooling1D(pool_size=2)\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        self.dense_layer = tf.keras.layers.Dense(units=num_phonemes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1d_layer(inputs)\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.flatten_layer(x)\n",
    "        output = self.dense_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pronunciation Model (PM) architecture\n",
    "class PronunciationModel(tf.keras.Model):\n",
    "    def __init__(self, num_phonemes, embedding_dim):\n",
    "        super(PronunciationModel, self).__init__()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=num_phonemes, output_dim=embedding_dim)\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(units=128, return_sequences=True)\n",
    "        self.dense_layer = tf.keras.layers.Dense(units=num_phonemes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        acoustic_features, auxiliary_embeddings = inputs\n",
    "        \n",
    "        # Pass the acoustic features through the embedding layer\n",
    "        acoustic_embeddings = self.embedding_layer(acoustic_features)\n",
    "        \n",
    "        # Concatenate the acoustic embeddings with the auxiliary embeddings\n",
    "        combined_embeddings = tf.concat([acoustic_embeddings, auxiliary_embeddings], axis=-1)\n",
    "        \n",
    "        # Pass the combined embeddings through LSTM layer\n",
    "        lstm_output = self.lstm_layer(combined_embeddings)\n",
    "        \n",
    "        # Pass LSTM output through dense layer\n",
    "        output = self.dense_layer(lstm_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pronunciation Error Detector (PED) architecture\n",
    "class PronunciationErrorDetector(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(PronunciationErrorDetector, self).__init__()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        phonemes, pronunciation_likelihoods, canonical_phonemes = inputs\n",
    "        \n",
    "        # Compute the alignment between canonical and recognized phoneme sequences\n",
    "        # Use dynamic programming algorithm\n",
    "        \n",
    "        # Compute the probabilities of mispronunciation\n",
    "        probabilities = tf.where(tf.equal(aligned_phonemes, recognized_phonemes), 0.0, 1.0 - pronunciation_likelihoods)\n",
    "        \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio file using librosa\n",
    "def load_audio(audio_path, sr=16000):\n",
    "    audio, _ = librosa.load(audio_path, sr=sr)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mel spectrogram features from audio\n",
    "def extract_mel_spectrogram(audio, sr=16000, n_fft=1024, hop_length=512, n_mels=80):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
